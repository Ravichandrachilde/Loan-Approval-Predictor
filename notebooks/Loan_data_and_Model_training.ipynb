{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97qHnIB6CmF4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/loan predictor/loan_data.csv')"
      ],
      "metadata": {
        "id": "6COYIJGsriYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "AXzgC5wjrs84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(columns=['loan_id'])"
      ],
      "metadata": {
        "id": "EohyBGw0sFbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "wrozDZh-t_vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "33q_30zdscC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "CgU3duMAsZCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns.tolist())"
      ],
      "metadata": {
        "id": "sW8GIZbJxJWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns = data.columns.str.strip()\n",
        "data"
      ],
      "metadata": {
        "id": "32i1c09SxW3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(data['residential_assets_value'] < 0).sum()"
      ],
      "metadata": {
        "id": "fLfiZyqutuLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Negative residential assets\n",
        "print(f\"Negative residential assets: {(data['residential_assets_value'] < 0).sum()}\")"
      ],
      "metadata": {
        "id": "QBV3pgpjzPoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data['residential_assets_value'] < 0, 'residential_assets_value'] = 0"
      ],
      "metadata": {
        "id": "uHicVmzi3sO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[data['bank_asset_value'] == 0].shape[0])"
      ],
      "metadata": {
        "id": "WYZzHCCizdJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "5OGnur4V1PoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['loan_status'] = data['loan_status'].str.strip()\n",
        "data['loan_status'] = data['loan_status'].map({'Approved': 1, 'Rejected': 0})"
      ],
      "metadata": {
        "id": "ySkl3Y9ZPOzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['loan_status'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "EjRsvxdA6kKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we can there there's class imbalance"
      ],
      "metadata": {
        "id": "mclA3qRg6v-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed feature engineering to address the multicollinearity I found in the heatmap.\n",
        "\n",
        "\n",
        "1. Interaction Feature: I created a loan_to_income ratio. This captures the applicant's repayment burden, which is a much stronger predictor of risk than raw income alone.\n",
        "\n",
        "\n",
        "2. Dimensionality Reduction: Since the asset classes were highly correlated, I aggregated them into total_assets."
      ],
      "metadata": {
        "id": "C49Abl0IAAta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['loan_to_income_ratio'] = data['loan_amount'] / data['income_annum']\n",
        "\n",
        "data['total_assets'] = (data['residential_assets_value'] +\n",
        "                        data['commercial_assets_value'] +\n",
        "                        data['luxury_assets_value'] +\n",
        "                        data['bank_asset_value'])"
      ],
      "metadata": {
        "id": "eeAw2-9Z9w2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping Unnecessary Columns"
      ],
      "metadata": {
        "id": "D1PvTyIKAgv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(columns=['loan_amount', 'income_annum',\n",
        "                          'residential_assets_value', 'commercial_assets_value',\n",
        "                          'luxury_assets_value', 'bank_asset_value'])"
      ],
      "metadata": {
        "id": "4U6IzGN_ApHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('loan_status', axis=1)\n",
        "y = data['loan_status']"
      ],
      "metadata": {
        "id": "cW1vCx4s1WK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test =train_test_split( X, y, test_size = 0.2, random_state=42,stratify=y)"
      ],
      "metadata": {
        "id": "9k-YFZg_25HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(f\"Categorical columns: {cat_cols}\")\n",
        "print(f\"Numerical columns: {num_cols}\")"
      ],
      "metadata": {
        "id": "1SFJccMVEK2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Distribution plots\n",
        "X_train.hist(figsize=(15, 10))"
      ],
      "metadata": {
        "id": "FG52NZ0S5HmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plots for outliers\n",
        "for col in num_cols:\n",
        "    plt.figure()\n",
        "    sns.boxplot(x=X_train[col])"
      ],
      "metadata": {
        "id": "28BMGiCn7f4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation Heatmap codedat\n",
        "plt.figure(figsize=(12, 8))\n",
        "corr_matrix = X_train[num_cols].corr()  # Use num_cols\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OitJVbM9Akeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', num_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "    ])"
      ],
      "metadata": {
        "id": "itl1qhqfBHmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
        "    \"XGBoost\": XGBClassifier(eval_metric='logloss', scale_pos_weight=10)\n",
        "    # Note: XGBoost uses 'scale_pos_weight' instead of 'class_weight' for imbalance\n",
        "}"
      ],
      "metadata": {
        "id": "Szj6WPcFM18X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    # Create the full pipeline: Preprocess -> Model\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    # Fit the pipeline\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    print(f\"--- {name} Report ---\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "Z1GtAVYQM8pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overfitting Check\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Train score\n",
        "    y_train_pred = pipeline.predict(X_train)\n",
        "    train_score = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "    # Test score\n",
        "    y_test_pred = pipeline.predict(X_test)\n",
        "    test_score = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(f\"Train Accuracy: {train_score:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_score:.4f}\")\n",
        "    print(f\"Difference: {abs(train_score - test_score):.4f}\")\n",
        "    print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "b3Hz3c9UPzcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBoost pipeline\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', models['XGBoost'])])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "import shap\n",
        "\n",
        "# 1. Setup Explainer\n",
        "explainer = shap.TreeExplainer(model.named_steps['classifier'])\n",
        "\n",
        "# 2. Transform Data\n",
        "X_train_transformed = model.named_steps['preprocessor'].transform(X_train)\n",
        "if hasattr(X_train_transformed, 'toarray'):\n",
        "    X_train_transformed = X_train_transformed.toarray()\n",
        "\n",
        "# 3. Calculate SHAP values\n",
        "shap_values = explainer.shap_values(X_train_transformed)\n",
        "\n",
        "# 4. Summary Plot\n",
        "shap.summary_plot(shap_values, X_train_transformed, feature_names=model.named_steps['preprocessor'].get_feature_names_out())\n",
        "\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value, shap_values[0,:], X_train_transformed[0,:], feature_names=model.named_steps['preprocessor'].get_feature_names_out())"
      ],
      "metadata": {
        "id": "XGQAJIbze-cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model saving\n",
        "import joblib\n",
        "\n",
        "model_path = '/content/drive/MyDrive/loan predictor/loan_model.joblib'\n",
        "joblib.dump(model, model_path)"
      ],
      "metadata": {
        "id": "r1fjT6Esf3wT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}